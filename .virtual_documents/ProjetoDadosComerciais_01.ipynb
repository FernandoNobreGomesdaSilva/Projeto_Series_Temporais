





#Import dos pacotes numpy e pandas
import numpy as np
import pandas as pd


#Abrindo o arquivo com o pandas
path = ('Dados_Comerciais.xlsx')
df = pd.read_excel(path)
df = pd.DataFrame(df)
df.head()


# Convertendo a coluna 'data' para o tipo datetime 
df['Data Venda'] = pd.to_datetime(df['Data Venda'])


df





#Inforando o número de linhas e colunas
df.shape


#Informando os tipos de dados
df.dtypes


#Selecionando apenas duas colunas do df
df_Ajuste = df[['Data Venda','ValorVenda']]


df_Ajuste.info()





# Calculando Q1, Q3 e IQR
Q1 = df_Ajuste['ValorVenda'].quantile(0.25)
Q3 = df_Ajuste['ValorVenda'].quantile(0.75)
IQR = Q3 - Q1


# Definindos os limites
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR


# Identificando os outliers com a criação da coluna: Outlier
df_Ajuste = df_Ajuste.copy()  # Garante que você está trabalhando com uma cópia
df_Ajuste.loc[:, 'Outlier'] = (df_Ajuste['ValorVenda'] < limite_inferior) | (df_Ajuste['ValorVenda'] > limite_superior)
df_Ajuste


# Conta quantos valores são ou não outliers
df_Ajuste['Outlier'].value_counts()


# Filtra apenas as linhas que são outliers
outliers = df_Ajuste[df_Ajuste['Outlier'] == True]
outliers


# Filtra linhas que não são outliers
nao_outliers = df_Ajuste[df_Ajuste['Outlier'] == False]
nao_outliers


#Visualização de Gráficos
import matplotlib.pyplot as plt
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 15, 4



plt.boxplot(df_Ajuste['ValorVenda'], vert=False)
plt.title('Boxplot dos Valores')
plt.show()





# Converter o DataFrame em uma série temporal com a coluna Data Venda como índice
serie_temporal1 = df_Ajuste.set_index('Data Venda')['ValorVenda']


print(serie_temporal1.index)  # Verifica se o índice está correto


type(serie_temporal1)


serie_temporal1


# Fornece a frequência da série temporal (Mensal, neste caso) acumulado.
serie_temporal1 = serie_temporal1.resample('ME').sum()
serie_temporal1


#Calculando a média anual
media_valor_venda = serie_temporal1.mean()
print('MÉDIA: {:.2f}'.format(media_valor_venda))


# Confirma se há valores nulos
print(serie_temporal1.isnull().sum())  


# Substituindo vírgulas por pontos e convertendo para numérico
serie_temporal1 = serie_temporal1.replace({',': ''}, regex=True)  # Remove vírgulas de milhares, se necessário
serie_temporal1 = pd.to_numeric(serie_temporal1, errors='coerce')  # Converte para numérico
# Confirmando a conversão
print("Último valor de serie_temporal (corrigido):", serie_temporal1.iloc[-1])


serie_temporal1.plot()
plt.xlabel('Data Venda')
plt.ylabel('ValorVenda')
plt.show()





from scipy import stats
import matplotlib.pyplot as plt

stats.probplot(serie_temporal1, dist="norm", plot=plt)
plt.title("Normal QQ plot")
plt.show()





# Executando o teste de Shapiro-Wilk para verificar a normalidade
e, p = stats.shapiro(serie_temporal1)
print('Estatística de teste: {}'.format(e))
print('p-valor: {}'.format(p))
# Avaliando o p-valor para decidir sobre a normalidade dos dados
if p > 0.05:
    print("Dados seguem uma distribuição normal")
else:
    print("Dados não seguem uma distribuição normal")





import statsmodels.tsa.stattools
import statsmodels.tsa.stattools as ts





# Realizando o teste KPSS
kpss_result = ts.kpss(serie_temporal1)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(kpss_result[0]))
print('p_valor: {:.4f}'.format(kpss_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in kpss_result[3].items():
    if kpss_result[0] > valor:
        print("Não é estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))
    else:
        print("É estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))





# Realizando o teste Dickey-Fuller
from statsmodels.tsa.stattools import adfuller

df_result = adfuller(serie_temporal1)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(df_result[0]))
print('p_valor: {:.4f}'.format(df_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in df_result[4].items():
    if df_result[0] < valor:  
        print("É estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))
    else:
        print("Não é estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))









from statsmodels.tsa.seasonal import seasonal_decompose


decomposicao = seasonal_decompose(serie_temporal1)


decomposicao.plot();





# Transformação por Log Transform (Diminui variância e melhorar normalidade)
serie_temporal2 = np.log(serie_temporal1)
serie_temporal2


# Executando o teste de Shapiro-Wilk para verificar a normalidade
e, p = stats.shapiro(serie_temporal2)
print('Estatística de teste: {}'.format(e))
print('p-valor: {}'.format(p))

# Avaliando o p-valor para decidir sobre a normalidade dos dados
if p > 0.05:
    print("Dados seguem uma distribuição normal")
else:
    print("Dados não seguem uma distribuição normal")


stats.probplot(serie_temporal1, dist="norm", plot=plt)
plt.title("Normal QQ plot Real ANTES da Transformação por logaritmo")
plt.show()


stats.probplot(serie_temporal2, dist="norm", plot=plt)
plt.title("Normal QQ plot Real ÁPOS da Transformação por logaritmo")
plt.show()


import seaborn as sns
sns.histplot(serie_temporal1, kde=True)
plt.title('Histograma ANTES da Transformação por logaritmo, indica dados não normalizados')
plt.show()


sns.histplot(serie_temporal2, kde=True)
plt.title('Histograma APOS da Transformação por logaritmo, indica dados normalizados')
plt.show()





# Realizando o teste KPSS
kpss_result = ts.kpss(serie_temporal2)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(kpss_result[0]))
print('p_valor: {:.4f}'.format(kpss_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in kpss_result[3].items():
    if kpss_result[0] > valor:
        print("Não é estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))
    else:
        print("É estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))


# Realizando o teste Dickey-Fuller
df_result = ts.adfuller(serie_temporal2)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(df_result[0]))
print('p_valor: {:.4f}'.format(df_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in df_result[4].items():
    if df_result[0] < valor:  
        print("É estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))
    else:
        print("Não é estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))








serie_temporal2_diff = serie_temporal2.diff().dropna()
print(serie_temporal2_diff)


# Realizando o teste KPSS
kpss_result = ts.kpss(serie_temporal2_diff, nlags=46)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(kpss_result[0]))
print('p_valor: {:.4f}'.format(kpss_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in kpss_result[3].items():
    if kpss_result[0] > valor:
        print("Não é estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))
    else:
        print("É estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))


# Realizando o teste Dickey-Fuller
df_result = ts.adfuller(serie_temporal2_diff)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(df_result[0]))
print('p_valor: {:.4f}'.format(df_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in df_result[4].items():
    if df_result[0] < valor:  
        print("É estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))
    else:
        print("Não é estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))





from statsmodels.graphics.tsaplots import plot_acf, plot_pacf


plot_acf(serie_temporal2, lags=20)
plt.show()


plot_acf(serie_temporal2_diff, lags=20)
plt.show()


plot_pacf(serie_temporal2, lags=20)
plt.show()


plot_pacf(serie_temporal2_diff, lags=20)
plt.show()





pip install pmdarima


from pmdarima.arima import auto_arima


### AUTOARIMA
# Ajustando o modelo AutoARIMA com base nos gráficos ACF e PACF
modelo_auto = auto_arima(
    serie_temporal2_diff,  # Série temporal diferenciada
    trace=True,            # Exibe informações no console
    stepwise=True,         # Busca otimizada nos parâmetros
    seasonal=True,         # Considera sazonalidade
    m=12,                  # Periodicidade sazonal (12 meses para dados mensais)
    start_p=1,             # Começa a busca para p em 1
    max_p=3,               # Limita p a um máximo de 3 (baseado no PACF)
    start_q=1,             # Começa a busca para q em 1
    max_q=3,               # Limita q a um máximo de 3 (baseado no ACF)
    start_P=0,             # Início para P (sazonal)
    max_P=2,               # Limita P sazonal a 2
    start_Q=0,             # Início para Q (sazonal)
    max_Q=2,               # Limita Q sazonal a 2
    d=1,                   # Diferenciação já aplicada (não busca d)
    D=1,                   # Componente sazonal diferencial
    max_order=10           # Limite para soma de p+q+P+Q (ajuste no desempenho)
)




print('Melhor modelo: ', modelo_auto.aic())


resultado_auto = modelo_auto.fit(serie_temporal2_diff)
print(resultado_auto.summary())





residuos_auto = resultado_auto.resid
residuos_auto()


plt.plot(residuos_auto())
plt.xlabel('Periodo')
plt.ylabel('Valores_Residuais')
plt.show()


#Seguem uma normalidade apos a aplicação do Auto Arima
stats.probplot(residuos_auto(), dist="norm", plot=plt)
plt.title("Normal QQ plot")
plt.show()


e, p = stats.shapiro(residuos_auto())
print('Estatística de teste: {}'.format(e))
print('p-valor: {}'.format(p))
# Avaliando o p-valor para decidir sobre a normalidade dos dados
if p > 0.05:
    print("Dados seguem uma distribuição normal")
else:
    print("Dados não seguem uma distribuição normal")





plot_acf(residuos_auto(), lags=20)
plt.xlabel('Lags')
plt.ylabel('Intervalo_Confiança')
plt.show()


plot_pacf(residuos_auto(), lags=20)
plt.xlabel('Lags')
plt.ylabel('Intervalo_Confiança')
plt.show()


plt.plot(serie_temporal2_diff, label='Série Real')
plt.plot(serie_temporal2_diff-residuos_auto(),color='red', label='Resíduos')
plt.xlabel('Periodo')
plt.ylabel('Valores_Residuais')
plt.legend(loc='best')
plt.show()


# Realizando o teste KPSS
kpss_result = ts.kpss(residuos_auto(), nlags=46)

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(kpss_result[0]))
print('p_valor: {:.4f}'.format(kpss_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in kpss_result[3].items():
    if kpss_result[0] > valor:
        print("Não é estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))
    else:
        print("É estacionária para o nível de significância de: {}=> {:.4f}".format(chave, valor))


df_result = ts.adfuller(residuos_auto())

# Exibindo os resultados do teste
print('Estatística do teste: {:.4f}'.format(df_result[0]))
print('p_valor: {:.4f}'.format(df_result[1]))
print('Valores Críticos:')

# Iterando pelos valores críticos e verificando se a série é estacionária
for chave, valor in df_result[4].items():
    if df_result[0] < valor:  
        print("É estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))
    else:
        print("Não é estacionária para o nível de significância de: {} => {:.4f}".format(chave, valor))





previsao_auto = resultado_auto.predict(n_periods=12)
previsao_auto





#Dados originais sem a diferenciação
serie_temporal1


#Dados com a diferenciação aplicada
serie_temporal2_diff


# Previsões log-transformadas (após o modelo AUTO_ARIMA e diferenciação)
previsao_auto = resultado_auto.predict(n_periods=12)
# Reverte transformação logarítmica
ultimo_valor_log = np.log(serie_temporal1.iloc[-1])  # Último valor log-transformado
previsoes_cumulativas = previsao_auto.cumsum() + ultimo_valor_log  # Soma cumulativa + último valor da serie_temporal1
previsoes_originais = np.exp(previsoes_cumulativas)  # Reverte para escala original
# Exibi resultados
print("Resultado da previsão:")
print(previsao_auto)
print("\nPrevisões cumulativas (log-transformadas):")
print(previsoes_cumulativas)
print("\nPrevisões na escala original:")
print(previsoes_originais)


previsoes_originais = pd.DataFrame(previsoes_originais)
indice_datas = pd.date_range(start='2016-01-31', periods=len(previsoes_originais), freq='ME')
previsoes_originais.index = indice_datas
previsoes_originais.columns = ['Data Venda']
previsoes_originais.columns = ['ValorVenda']
previsoes_originais


serie_temporal1 = pd.DataFrame(serie_temporal1)
indice_datas = pd.date_range(start='2012-01-31', periods=len(serie_temporal1), freq='ME')
serie_temporal1.index = indice_datas
serie_temporal1.columns = ['Data Venda']
serie_temporal1.columns = ['ValorVenda']
serie_temporal1


seriecomprevisao = pd.concat([serie_temporal1, previsoes_originais], axis=0,ignore_index=True)
seriecomprevisao


previsoes_originais.index = range(59, len(previsoes_originais)+59)
previsoes_originais


seriecomprevisao.plot()
plt.plot(previsoes_originais, color='red', label='Previsão')
plt.legend(loc='best')
plt.show()


serie_temporal1 = pd.DataFrame(serie_temporal1)
indice_datas = pd.date_range(start='2012-01-31', periods=len(serie_temporal1), freq='ME')
#serie_temporal1.index = indice_datas
serie_temporal1.columns = ['Data Venda']
serie_temporal1.columns = ['ValorVenda']
serie_temporal1


previsoes_originais = pd.DataFrame(previsoes_originais)
indice_datas = pd.date_range(start='2016-01-31', periods=len(previsoes_originais), freq='ME')
previsoes_originais.index = indice_datas
previsoes_originais.columns = ['Data Venda']
previsoes_originais.columns = ['ValorVenda']
previsoes_originais


seriecomprevisaoMensal = pd.concat([serie_temporal1, previsoes_originais], axis=0,ignore_index=False)
seriecomprevisaoMensal


seriecomprevisaoMensal['Data Venda'] = seriecomprevisaoMensal.index
seriecomprevisaoMensal.reset_index(drop=True, inplace=True)
seriecomprevisaoMensal


# Extraímos o ano criando nova variável
seriecomprevisaoMensal['Data Venda'] = seriecomprevisaoMensal['Data Venda'].dt.year
seriecomprevisaoMensal


#Reorganizando as colunas por 'Data Venda'.
#df = df.rename(columns={'Data Venda': 'Data_Venda', 'ValorVenda': 'Valor_Venda'})
seriecomprevisaoAnual = seriecomprevisaoMensal[['Data Venda', 'ValorVenda']]
seriecomprevisaoAnual = seriecomprevisaoMensal.rename(columns={'Data Venda':'Venda_Acumul_Anual', 'ValorVenda':'Valor_Anual_Venda'})
seriecomprevisaoAnual


import locale
# Configurando o locale para o padrão monetário brasileiro
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')
# Agrupando os dados por ano e somando os valores de cada ano
dados_agrupados = seriecomprevisaoAnual.groupby('Venda_Acumul_Anual')['Valor_Anual_Venda'].sum()
# Criando uma lista de cores alternadas
cores = ['skyblue', 'blue'] * (len(dados_agrupados) // 2 + 1)
# Criando o gráfico de barras
fig, ax = plt.subplots(figsize=(14, 6))
barras = ax.bar(dados_agrupados.index, dados_agrupados.values, color=cores[:len(dados_agrupados)])
# Adicionando os valores dentro das barras, formatados como moeda brasileira
for barra in barras:
    altura = barra.get_height()
    ax.text(
        barra.get_x() + barra.get_width() / 2,           # Posição no eixo X
        altura - (altura * 0.1),                         # Posição no eixo Y
        locale.currency(altura, grouping=True),          # Texto formatado como moeda
        ha='center', va='bottom', color='black'          # Alinhamento e cor
    )
# Personalizando o gráfico
plt.title('Histórico de vendas por ano e previsão para 2016')
plt.xlabel('Ano')
plt.ylabel('Valor Total (R$)')
#Ajustando a grid para ficar atrás das linhas
ax.set_axisbelow(True)  # Coloca as grades atrás dos dados
plt.grid(True, linestyle='--', alpha=0.7)  # Ajusta o estilo e a opacidade da grade
# Exibe o gráfico
plt.show()


previsoes_originais['Data Venda'] = previsoes_originais.index
previsoes_originais.reset_index(drop=True, inplace=True)
previsoes_originais


# Copia a previsão dos dados para o mesmo diretório inicial
previsoes_originais.to_excel('Dados_Comerciais_Previsão.xlsx', index=False)


# Convertendo a coluna 'Data Venda' para o formato datetime (se ainda não estiver)
previsoes_originais['Data Venda'] = pd.to_datetime(previsoes_originais['Data Venda'])
previsoes_originais


import locale
# Configurando o locale para o padrão monetário brasileiro
locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')
# Convertendo a coluna 'Data Venda' para o formato datetime
previsoes_originais['Data Venda'] = pd.to_datetime(previsoes_originais['Data Venda'])

# Extraindo apenas o mês para exibição no gráfico
previsoes_originais['Mes'] = previsoes_originais['Data Venda'].dt.strftime('%b')

# Criando uma lista de cores alternadas
cores = ['skyblue', 'blue'] * (len(previsoes_originais) // 2 + 1)

# Criando o gráfico de barras
fig, ax = plt.subplots(figsize=(14, 6))
barras = ax.bar(previsoes_originais['Mes'], previsoes_originais['ValorVenda'], color=cores[:len(previsoes_originais)])

# Adicionando os valores dentro das barras, formatados como moeda brasileira
for barra in barras:
    altura = barra.get_height()
    ax.text(
        barra.get_x() + barra.get_width() / 2,           # Posição no eixo X
        altura - (altura * 0.1),                         # Posição no eixo Y
        locale.currency(altura, grouping=True),          # Texto formatado como moeda
        ha='center', va='bottom', color='black'          # Alinhamento e cor
    )

# Personalizando o gráfico
plt.title('Previsão mensal do ano de 2016')
plt.xlabel('Meses')
plt.ylabel('Valor Total (R$)')
plt.grid(True, linestyle='--', alpha=0.7)  # Ajusta o estilo e a opacidade da grade

# Exibe o gráfico
plt.show()


from sklearn.metrics import mean_absolute_error, mean_squared_error





# Lista com valores reais de 2015
lista = [
    '10305.57',
    '14372.22',
    '17812.00',
    '16902.45',
    '19898.00',
    '13103.87',
    '14581.00',
    '10455.00',
    '14942.00',
    '9147.34',
    '15519.34',
    '8026.00']
valores_reais = pd.DataFrame(lista, columns = ['valores reais'])
print(valores_reais)



auto = previsoes_originais.iloc[0:12].reset_index(drop=True)
auto


auto = auto.rename(columns={'ValorVenda': 'Previsão_SARIMA'})
auto


desempenho = pd.concat([valores_reais, auto],axis=1)
desempenho


desempenho = desempenho[['valores reais','Previsão_SARIMA']]
desempenho





print('ERRO MÉDIO ABSOLUTO (MAE)') # media_valor_venda
mae_sarima = mean_absolute_error(desempenho['valores reais'], desempenho['Previsão_SARIMA'])
print('SARIMA: {:.2f}'.format(mae_sarima))

try:
    print('MÉDIA: {:.2f}'.format(media_valor_venda))
except NameError:
    print('Erro: A variável "media_valor_venda" não foi definida.')
    
resultado = (lambda mae_sarima, media: 'Modelo aprovado' if mae_sarima < media else 'Modelo não aprovado')(mae_sarima, media_valor_venda)
print(resultado)






print('ERRO QUADRÁTICO MÉDIO (MSE)')
mse_sarima = mean_squared_error(desempenho['valores reais'], desempenho['Previsão_SARIMA'])
print('SARIMA: {:.2f}'.format(mse_sarima))

def calcular_media_valor_venda(media_valor_venda):
    media_valor_venda_ao_quadrado = media_valor_venda ** 2
    return media_valor_venda_ao_quadrado

try:
    media_ao_quadrado = calcular_media_valor_venda(media_valor_venda)
    print('MÉDIA: {:.2f}'.format(media_ao_quadrado))
    
    percentual_mse = (mse_sarima / media_ao_quadrado) * 100
    print('%: {:.2f}'.format(percentual_mse))

    if percentual_mse < 10:
        print('Modelo excelente')
    elif percentual_mse < 30:
        print('Modelo bom')
    elif percentual_mse < 50:
        print('Modelo razoável')
    else:
        print('Modelo rejeitado')

except NameError:
    print('Erro: A variável "media_valor_venda" não foi definida.')






from sklearn.metrics import mean_squared_error
print('RAIZ DO ERRO QUADRÁTICO MÉDIO (RMSE)')
mse_sarima = mean_squared_error(desempenho['valores reais'], desempenho['Previsão_SARIMA'])
rmse_sarima = np.sqrt(mse_sarima)
print('SARIMA: {:.2f}'.format(rmse_sarima))

try:
    print('MÉDIA: {:.2f}'.format(media_valor_venda))
except NameError:
    print('Erro: A variável "media_valor_venda" não foi definida.')

resultado = (lambda rmse_sarima, media: 'Modelo aprovado' if rmse_sarima < media else 'Modelo não aprovado')(rmse_sarima, media_valor_venda)
print(resultado)






print('ERRO PERCENTUAL MÉDIA ABSOLUTO (MAPE)')
desempenho.loc[:, 'valores reais'] = pd.to_numeric(desempenho['valores reais'], errors='coerce')
mape_sarima = np.mean(np.abs((desempenho['valores reais'] - desempenho['Previsão_SARIMA']) / desempenho['valores reais'])) * 100
print('SARIMA: {:.2f}%'.format(mape_sarima))

try:
    print('MÉDIA: {:.2f}'.format(media_valor_venda))
except NameError:
    print('Erro: A variável "media_valor_venda" não foi definida.')
    
if mape_sarima < 10: 
    print('Modelo excelente')
elif mape_sarima < 20: 
    print('Modelo bom')
elif mape_sarima < 50:
    print('Modelo razoável') 
else: 
    print('Modelo ruim')




